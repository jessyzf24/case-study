{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d91e7b8-2984-4190-a7ce-eb9e9fdd878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929d298e-b20e-434d-9583-4adf88c0dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('case_study')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f6ed3-8586-45d4-8d19-8cc9543f3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj structure\n",
    "# -input\n",
    "#     --train.csv\n",
    "#     --test.csv\n",
    "# -src\n",
    "#     --data_preprocess.py\n",
    "#     --create_folds.py\n",
    "#     --config.py\n",
    "#     --model_dispatcher.py\n",
    "#     --train.py\n",
    "#     --inference.py\n",
    "# -models\n",
    "# -README.md\n",
    "# -main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b4c6b5-d867-445f-8f54-8892bc441b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/data_preprocess.py\n",
    "\n",
    "def data_preprocess():\n",
    "    '''Preprocess data\n",
    "    '''\n",
    "    data_dir = Path('case_study/input')\n",
    "    filepath = data_dir / 'DataScientist_CaseStudy_Dataset.xlsx'\n",
    "    sheetnames = ['Description', 'Soc_Dem', 'Products_ActBalance', 'Inflow_Outflow', 'Sales_Revenues']\n",
    "    \n",
    "    sheet_id = 4\n",
    "    df_sales_rev = pd.read_excel(filepath, sheet_name=sheetnames[sheet_id])\n",
    "    \n",
    "    sheet_id = 1\n",
    "    df_user = pd.read_excel(filepath, sheet_name=sheetnames[sheet_id])\n",
    "    \n",
    "    sheet_id = 2\n",
    "    df_acct = pd.read_excel(filepath, sheet_name=sheetnames[sheet_id])\n",
    "    \n",
    "    sheet_id = 3\n",
    "    df_inout = pd.read_excel(filepath, sheet_name=sheetnames[sheet_id])\n",
    "    \n",
    "    # convert the column name to lowercase\n",
    "    df_acct.columns = [col.lower() for col in df_acct.columns]\n",
    "    df_user.columns = [col.lower() for col in df_user.columns]\n",
    "    df_inout.columns = [col.lower() for col in df_inout.columns]\n",
    "    df_sales_rev.columns = [col.lower() for col in df_sales_rev.columns]\n",
    "    \n",
    "    df = (\n",
    "        df_user.merge(df_acct, on='client', how='inner')\n",
    "        .merge(df_inout, on='client', how='outer')\n",
    "        .merge(df_sales_rev, on='client', how='outer')\n",
    "    )\n",
    "    \n",
    "    df_test = df[~df['client'].isin(df_sales_rev.client.unique())]\n",
    "    filepath = data_dir / 'test.csv'\n",
    "    df_test.to_csv(filepath, index=False)\n",
    "    \n",
    "    df = df[df['client'].isin(df_sales_rev.client.unique())]\n",
    "    \n",
    "    # process categorical variables\n",
    "    df.loc[:, 'sex'] = df.sex.fillna('NONE')\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    df.loc[:, 'sex'] = lbl_enc.fit_transform(df.sex.values)\n",
    "    \n",
    "    encoder_fp = data_dir / 'sex_lbl_enc.bin'\n",
    "    joblib.dump(lbl_enc, encoder_fp)\n",
    "    \n",
    "    for target_col in ['sale_mf', 'sale_cc', 'sale_cl']:\n",
    "        df['target'] = np.where(df[target_col], 1, 0)\n",
    "        print(f'Target: {target_col}')\n",
    "        print(f'df.target.value_counts(): {df.target.value_counts()}')\n",
    "        \n",
    "        filepath = data_dir / f'{target_col}.csv'\n",
    "        df.to_csv(filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757bee3c-4f9e-4c7d-aa8b-0e8a271053f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/create_folds.py\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "def create_folds(fp_read, fp_save):\n",
    "    '''Create folds for classfication problem\n",
    "    '''\n",
    "    df = pd.read_csv(fp_read)\n",
    "\n",
    "    df['kfold'] = -1\n",
    "\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    y = df.target.values\n",
    "    \n",
    "    for fold, (trn_, val_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[val_, 'kfold'] = fold\n",
    "\n",
    "    df.to_csv(fp_save, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e203bf0a-53bf-48e8-90a3-218fbcaff470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feats to use: 30\n"
     ]
    }
   ],
   "source": [
    "# src/config.py\n",
    "\n",
    "FEAT_COLS = [\n",
    " 'client',\n",
    " 'sex',\n",
    " 'age',\n",
    " 'tenure',\n",
    " 'count_ca',\n",
    " 'count_sa',\n",
    " 'count_mf',\n",
    " 'count_ovd',\n",
    " 'count_cc',\n",
    " 'count_cl',\n",
    " 'actbal_ca',\n",
    " 'actbal_sa',\n",
    " 'actbal_mf',\n",
    " 'actbal_ovd',\n",
    " 'actbal_cc',\n",
    " 'actbal_cl',\n",
    " 'volumecred',\n",
    " 'volumecred_ca',\n",
    " 'transactionscred',\n",
    " 'transactionscred_ca',\n",
    " 'volumedeb',\n",
    " 'volumedeb_ca',\n",
    " 'volumedebcash_card',\n",
    " 'volumedebcashless_card',\n",
    " 'volumedeb_paymentorder',\n",
    " 'transactionsdeb',\n",
    " 'transactionsdeb_ca',\n",
    " 'transactionsdebcash_card',\n",
    " 'transactionsdebcashless_card',\n",
    " 'transactionsdeb_paymentorder']\n",
    "print(f'number of feats to use: {len(FEAT_COLS)}')\n",
    "\n",
    "DATA_DIR = Path('/case_study/input')\n",
    "MODEL_DIR = Path('/case_study/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5b0d9-63ff-45ef-9140-681f2c08fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/model_dispatcher.py\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "# import lightgbm as lgbm\n",
    "\n",
    "models = {\n",
    "    'decision_tree_gini': tree.DecisionTreeClassifier(\n",
    "        criterion='gini'\n",
    "    ),\n",
    "    'decision_tree_entropy': tree.DecisionTreeClassifier(\n",
    "        criterion='entropy'\n",
    "    ),\n",
    "    'rf': ensemble.RandomForestClassifier(),\n",
    "    # 'lgbm': lgbm.LGBMClassifier(\n",
    "    #     boosting_type='gbdt', \n",
    "    #     num_leaves=31, \n",
    "    #     max_depth=-1, \n",
    "    #     learning_rate=0.1, \n",
    "    #     n_estimators=100, \n",
    "    #     subsample_for_bin=200000, \n",
    "    #     objective=None, \n",
    "    #     class_weight=None, \n",
    "    #     min_split_gain=0.0, \n",
    "    #     min_child_weight=0.001, \n",
    "    #     min_child_samples=20, \n",
    "    #     subsample=1.0, \n",
    "    #     subsample_freq=0, \n",
    "    #     colsample_bytree=1.0, \n",
    "    #     reg_alpha=0.0, \n",
    "    #     reg_lambda=0.0, \n",
    "    #     random_state=42, \n",
    "    #     n_jobs=None, \n",
    "    #     importance_type='split'\n",
    "    # )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf066455-3538-44ea-ad31-92155fb2b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/train.py\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def run(fold, model_name, target_col):\n",
    "    '''Train model\n",
    "    '''\n",
    "    fp = DATA_DIR / f'{target_col}_train_folds.csv'\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train = df_train[FEAT_COLS].values\n",
    "    y_train = df_train.target.values\n",
    "\n",
    "    x_valid = df_valid[FEAT_COLS].values\n",
    "    y_valid = df_valid.target.values\n",
    "\n",
    "    clf = models[model_name]\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    preds = clf.predict(x_valid)\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_valid, preds)\n",
    "    print(f'Fold={fold}, ROC AUC={auc}')\n",
    "\n",
    "    model_fp = MODEL_DIR / f'{target_col}_{model_name}_{fold}.bin'\n",
    "    joblib.dump(clf, model_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156072b8-9e84-42fe-ae57-58cb4f750fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/inference.py\n",
    "\n",
    "def get_inference(target_col):\n",
    "    '''Get inference\n",
    "    '''\n",
    "    filepath = DATA_DIR / 'test.csv'\n",
    "    df_test = pd.read_csv(filepath)\n",
    "    \n",
    "    encoder_fp = DATA_DIR / 'sex_lbl_enc.bin'\n",
    "    lbl_enc = joblib.load(encoder_fp)\n",
    "    \n",
    "    df_test.loc[:, 'sex'] = df_test['sex'].fillna('NONE')\n",
    "    df_test.loc[:, 'sex'] = lbl_enc.transform(df_test['sex'].values)\n",
    "    \n",
    "    x_test = df_test[FEAT_COLS].values\n",
    "    model_name = 'rf'\n",
    "    pred_lst = []\n",
    "    probs_lst = []\n",
    "    for fold in range(5):\n",
    "        model_fp = MODEL_DIR / f'{target_col}_{model_name}_{fold}.bin'\n",
    "        model = joblib.load(model_fp)\n",
    "        \n",
    "        probs = model.predict_proba(x_test)\n",
    "        \n",
    "        preds = np.argmax(probs, axis=1, keepdims=True)\n",
    "        probs = np.take_along_axis(probs, preds, axis=1)\n",
    "        \n",
    "        probs_lst.append(probs)\n",
    "        pred_lst.append(preds)\n",
    "        \n",
    "    thresh = 0.5\n",
    "    preds = (np.mean(np.array(pred_lst), axis=0) > thresh).astype(int)\n",
    "    probs = np.mean(np.array(probs_lst), axis=0)\n",
    "    \n",
    "    df_pred = pd.DataFrame(\n",
    "        data={\n",
    "            'client': df_test.client.values,\n",
    "            f'preds_{target_col}': preds.squeeze(),\n",
    "            f'probs_{target_col}': probs.squeeze()\n",
    "        }\n",
    "    )\n",
    "    pred_fp = DATA_DIR / f'pred_{target_col}.csv'\n",
    "    df_pred.to_csv(pred_fp, index=False)\n",
    "\n",
    "    return df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422bde95-d6d3-4b8c-9d7f-fe014193bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Step 1. Data Preprocessing, create train and test dataset======\n",
      "Target: sale_mf\n",
      "df.target.value_counts(): target\n",
      "0    776\n",
      "1    193\n",
      "Name: count, dtype: int64\n",
      "Target: sale_cc\n",
      "df.target.value_counts(): target\n",
      "0    727\n",
      "1    242\n",
      "Name: count, dtype: int64\n",
      "Target: sale_cl\n",
      "df.target.value_counts(): target\n",
      "0    679\n",
      "1    290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======Step 2. Create cross validation for sale_mf======\n",
      "\n",
      "======Step 3. Run rf for target sale_mf======\n",
      "Fold=0, ROC AUC=0.5330634278002699\n",
      "Fold=1, ROC AUC=0.5511993382961126\n",
      "Fold=2, ROC AUC=0.5095947063688998\n",
      "Fold=3, ROC AUC=0.5256410256410257\n",
      "Fold=4, ROC AUC=0.5362478777589135\n",
      "\n",
      "======Step 2. Create cross validation for sale_cc======\n",
      "\n",
      "======Step 3. Run rf for target sale_cc======\n",
      "Fold=0, ROC AUC=0.562785388127854\n",
      "Fold=1, ROC AUC=0.593892694063927\n",
      "Fold=2, ROC AUC=0.5679802955665024\n",
      "Fold=3, ROC AUC=0.5711470795214638\n",
      "Fold=4, ROC AUC=0.5799568965517241\n",
      "\n",
      "======Step 2. Create cross validation for sale_cl======\n",
      "\n",
      "======Step 3. Run rf for target sale_cl======\n",
      "Fold=0, ROC AUC=0.5727687626774849\n",
      "Fold=1, ROC AUC=0.55552738336714\n",
      "Fold=2, ROC AUC=0.5789807302231237\n",
      "Fold=3, ROC AUC=0.528524340770791\n",
      "Fold=4, ROC AUC=0.5578544061302682\n",
      "\n",
      "======Step 4. Get inference======\n",
      "\n",
      "======Step 5. Select top clients======\n",
      "\n",
      "======Step 6. Get final revenue======\n",
      "\n",
      "mean_mf: 9.66\n",
      "mean_cc: 10.86\n",
      "mean_cl: 12.04\n",
      "final revenue: 931.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'\\n======Step 1. Data Preprocessing, create train and test dataset======')\n",
    "data_dir = Path('case_study/input')\n",
    "data_preprocess()\n",
    "\n",
    "model_name = 'rf'\n",
    "for target_col in ['sale_mf', 'sale_cc', 'sale_cl']:\n",
    "    fp_read = data_dir / f'{target_col}.csv'\n",
    "    fp_save = data_dir / f'{target_col}_train_folds.csv'\n",
    "    print(f'\\n======Step 2. Create cross validation for {target_col}======')\n",
    "    create_folds(fp_read, fp_save)\n",
    "\n",
    "    print(f'\\n======Step 3. Run {model_name} for target {target_col}======')\n",
    "    for fold in range(5):\n",
    "        run(fold=fold, model_name=model_name, target_col=target_col)\n",
    "\n",
    "print(f'\\n======Step 4. Get inference======')\n",
    "df_pred_sale_mf = get_inference(target_col='sale_mf')\n",
    "df_pred_sale_cc = get_inference(target_col='sale_cc')\n",
    "df_pred_sale_cl = get_inference(target_col='sale_cl')\n",
    "\n",
    "\n",
    "# combine the preds, get the top clients\n",
    "print(f'\\n======Step 5. Select top clients======')\n",
    "df_pred = (\n",
    "    df_pred_sale_mf.merge(df_pred_sale_cc, on='client', how='inner')\n",
    "    .merge(df_pred_sale_cl, on='client', how='inner')\n",
    ")\n",
    "\n",
    "df_pred['offer_cnt'] = df_pred['preds_sale_mf'] + df_pred['preds_sale_cc'] + df_pred['preds_sale_cl']\n",
    "\n",
    "df_pred['final_offer'] = np.where(\n",
    "    df_pred['offer_cnt'] > 0,\n",
    "    df_pred[['probs_sale_mf', 'probs_sale_cc', 'probs_sale_cl']].idxmax(axis=1),\n",
    "    'No offer'\n",
    ")\n",
    "\n",
    "df_pred['sale_mf'] = np.where(\n",
    "    df_pred['final_offer'].str.contains('sale_mf'), 1, 0\n",
    ")\n",
    "df_pred['sale_cc'] = np.where(\n",
    "    df_pred['final_offer'].str.contains('sale_cc'), 1, 0\n",
    ")\n",
    "df_pred['sale_cl'] = np.where(\n",
    "    df_pred['final_offer'].str.contains('sale_cl'), 1, 0\n",
    ")\n",
    "\n",
    "fp_save = DATA_DIR / 'pred_sale.csv'\n",
    "df_top = df_pred[df_pred['offer_cnt'] > 0][['client', 'sale_mf', 'sale_cc', 'sale_cl']]\n",
    "df_top.to_csv(fp_save, index=False)\n",
    "\n",
    "print(f'\\n======Step 6. Get final revenue======')\n",
    "fp_read = data_dir / f'{target_col}.csv'\n",
    "df = pd.read_csv(fp_read)\n",
    "\n",
    "mean_mf = df[df['sale_mf'] == 1].revenue_mf.mean()\n",
    "mean_cc = df[df['sale_cc'] == 1].revenue_cc.mean()\n",
    "mean_cl = df[df['sale_cl'] == 1].revenue_cl.mean()\n",
    "print(\n",
    "    f'\\nmean_mf: {mean_mf:.2f}'\n",
    "    f'\\nmean_cc: {mean_cc:.2f}'\n",
    "    f'\\nmean_cl: {mean_cl:.2f}'\n",
    ")\n",
    "\n",
    "final_revenue = df_top['sale_mf'].sum() * mean_mf + df_top['sale_cc'].sum() * mean_cc + df_top['sale_cl'].sum() * mean_cl\n",
    "print(f'final revenue: {final_revenue:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ef297-ef96-46e5-afcf-489508bd7006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
